<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ekdeep Singh Lubana</title>
  
  <meta name="author" content="Ekdeep Singh Lubana">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ekdeep Singh Lubana</name>
              </p>

        <!-- Description -->
              <p>I am a PhD candidate in EECS Department at the University of Michigan, advised by <a href="http://robertdick.org/">Robert Dick</a>. I am also affiliated with Harvard Center for Brain Science, where I am mentored by <a href="https://sites.google.com/view/htanaka/home">Hidenori Tanaka</a>.
              </p>
              <p>
                I am generally interested in designing theoretically motivated, grounded algorithms for practical applications of DNNs. I am also very interested in better understanding training dynamics of neural networks, especially via a statistical physics perspective. 
              </p>
              <p>
                I graduated with a Bachelor's degree in ECE from Indian Institute of Technology (IIT), Roorkee in 2019. My research in undergraduate was primarily focused on embedded systems, such as energy-efficient machine vision systems.
              </p>

        <!-- Stuff -->
              <p style="text-align:center">
                <a href="mailto:eslubana@umich.edu">Email</a> &nbsp/&nbsp
                <a href="data/ekdeep-cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=OP7S3vsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
<!--                 <a href="https://twitter.com/EkdeepL">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/EkdeepSLubana">Github</a>
              </p>
            </td>

        <!-- Front image -->
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/ekdeep.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/ekdeep.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <!-- News -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr> <td width="100%" valign="top">
        <heading>News</heading>
        <table width="100%" valign="top" border="0" cellspacing="0" cellpadding="2">

        <tr valign="top"> <td> [04/2023] </td>  <td> 
        Our work on <a href="https://arxiv.org/abs/2211.08422">a mechanistic understanding of loss landscapes</a> was accepted to ICML, 2023.  
        </td> </tr>

          
        <tr valign="top"> <td> [01/2023] </td>  <td> 
        Our work analyzing <a href="https://arxiv.org/pdf/2210.00638.pdf">loss landscape of self-supervised objectives</a> was accepted to ICLR, 2023.  
        </td> </tr>

          
        <tr valign="top"> <td> [09/2022] </td>  <td> 
        Our work on <a href="https://arxiv.org/abs/2111.03220">data-centric analysis of graph contrastive learning</a> was accepted to NeurIPS, 2022.  
        </td> </tr>

          
        <tr valign="top"> <td> [05/2022] </td>  <td> 
        Our work on <a href="https://arxiv.org/abs/2205.11506">unsupervised federated learning</a> was accepted as a <font color="red">spotlight</font> at ICML, 2022!
        </td> </tr>

          
        <tr valign="top"> <td> [05/2022] </td>  <td> 
        Joining Harvard Center for Brain Science as a research affiliate!
        </td> </tr>

          
        <tr valign="top"> <td> [10/2021] </td>  <td> 
        Our work on <a href="https://arxiv.org/abs/2106.05956">dynamics of normalization layers</a> was accepted to NeurIPS, 2021.  
        </td> </tr>

          
<!--         <tr valign="top"> <td> [05/2021] </td>  <td> 
        I will be interning with <a href="https://sites.google.com/view/htanaka/home/">Hidenori Tanaka</a> at <a href="https://ntt-research.com/phi/">Physics and Informatics Lab, NTT Research</a> this summer.
        </td> </tr>
 -->
          <tr valign="top"> <td> [03/2021] </td>  <td> 
        Our work on <a href="https://openreview.net/forum?id=rumv7QmLUue">theory of pruning</a> was accepted as a <font color="red">spotlight</font> at ICLR, 2021.  
        </td> </tr>

        </table>
        </td>  </tr> </tbody></table>


        <!-- Publications -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/mmc.png" alt="ssl_landscape" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2211.08422">
                <papertitle>Mechanistic Mode Connectivity</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="https://psychology.fas.harvard.edu/people/eric-bigelow">Eric J. Bigelow</a>,
              <a href="http://robertdick.org/">Robert P. Dick</a>,
              <a href="https://www.davidscottkrueger.com">David Krueger</a>, and
              <a href="https://sites.google.com/view/htanaka/home">Hidenori Tanaka</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2023
              <br> 
              <a href="data/mmc.bib">bibtex</a> / <a href="https://arxiv.org/abs/2211.08422">arXiv</a> / <a href="https://github.com/EkdeepSLubana/MMC"> github </a>
              <p>We show models that rely on entirely different mechanisms for making their predictions can exhibit mode connectivity, but generally the ones that are mechanistically similar are linearly connected.</p>
            </td>
          </tr>
          
          

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ssl_landscape.png" alt="ssl_landscape" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2210.00638.pdf">
                <papertitle>What Shapes the Landscape of Self-Supervised Learning?</papertitle>
              </a>
              <br>
              <a href="http://cat.phys.s.u-tokyo.ac.jp/~zliu/">Liu Ziyin</a>, 
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="http://cat.phys.s.u-tokyo.ac.jp/~ueda/E_index.html">Masahito Ueda</a>, and
              <a href="https://sites.google.com/view/htanaka/home">Hidenori Tanaka</a>
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2023
              <br> 
              <a href="data/ssl_landscape.bib">bibtex</a> / <a href="https://arxiv.org/pdf/2210.00638.pdf">arXiv</a> 
              <p>We present a highly detailed analysis of the landscape of several self-supervised learning objectives to clarify the role of representational collapse.</p>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/graphssl.png" alt="GraphSSL" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2208.02810">
                <papertitle>Analyzing Data-Centric Properties for Contrastive Learning on Graphs</papertitle> 
              </a>
              <br>
              <a href="http://www-personal.umich.edu/~pujat/">Puja Trivedi</a>,
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="https://markheimann.github.io">Mark Heimann</a>,
              <a href="https://web.eecs.umich.edu/~dkoutra/">Danai Koutra</a>, and
              <a href="https://jjthiagarajan.com">Jay Jayaraman Thiagarajan</a>
              <br>
              <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2022
              <br>
              <a href="data/graphssl.bib">bibtex</a> / <a href="https://arxiv.org/abs/2208.02810">arXiv</a> / <a href="https://github.com/pujacomputes/datapropsgraphSSL">github</a>
              <p>We propose a theoretical framework that demonstrates limitations of popular graph augmentation strategies for self-supervised learning.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/orchestra.png" alt="Orchestra" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2205.11506">
                <papertitle>Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering</papertitle> 
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="https://iantangc.github.io">Chi Ian Tang</a>,
              <a href="https://www.fahim-kawsar.net">Fahim Kawsar</a>,
              <a href="http://robertdick.org/">Robert P. Dick</a>, and
              <a href="http://akhilmathurs.github.io">Akhil Mathur</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2022 <font color="red"> (Spotlight)</font> 
              <br>
              <a href="data/orchestra.bib">bibtex</a> / <a href="https://arxiv.org/abs/2205.11506">arXiv</a> / <a href="https://github.com/akhilmathurs/orchestra">github</a> / <a href="https://slideslive.com/38984080/orchestra-unsupervised-federated-learning-via-globally-consistent-clustering">video</a> 
              <p>We propose an unsupervised learning method that exploits client heterogeneity to enable privacy preserving, SOTA performance unsupervised federated learning.</p>
            </td>
          </tr>


<!--           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/www.png" alt="www" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2111.03220.pdf">
                <papertitle>Augmentations in Graph Contrastive Learning: Current Methodological Flaws & Towards Better Practices</papertitle>
              </a>
              <br>
              <a href="http://www-personal.umich.edu/~pujat/">Puja Trivedi</a>,
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="https://sites.google.com/umich.edu/yujunyan/home">Yujun Yan</a>,
              <a href="https://sites.google.com/site/yangyaoqingcmu/">Yaoqing Yang</a>, and
              <a href="https://web.eecs.umich.edu/~dkoutra/">Danai Koutra</a>
              <br>
              <em>ACM The Web Conference (formerly WWW)</em>, 2022
              <br>
              <a href="data/www.bib">bibtex</a> / <a href="https://arxiv.org/abs/2111.03220">arXiv</a>
              <p>We contextualize the performance of several unsupervised graph representation learning methods with respect to inductive bias of GNNs and show significant improvements by using structured augmentations defined by task-relevance.</p>
            </td>
          </tr>
 -->

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/beyondbn.png" alt="beyondbn" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2106.05956.pdf">
                <papertitle>Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="https://sites.google.com/view/htanaka/home">Hidenori Tanaka</a>, and
              <a href="http://robertdick.org/">Robert P. Dick</a>
              <br>
              <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021
              <br>
              <a href="data/beyondbn.bib">bibtex</a> / <a href="https://github.com/EkdeepSLubana/BeyondBatchNorm">github</a> / <a href="https://arxiv.org/abs/2106.05956">arXiv</a> / <a href="https://slideslive.com/38969102/beyond-batchnorm-towards-a-unified-understanding-of-normalization-in-deep-learning?ref=recommended">video</a> 
              <p>We develop a general theory to understand the role of normalization layers in improving training dynamics of a neural network at initialization.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/collas.png" alt="quadreg" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2102.02805.pdf">
                <papertitle>How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role of Interpolation</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="http://www-personal.umich.edu/~pujat/">Puja Trivedi</a>,
              <a href="https://web.eecs.umich.edu/~dkoutra/">Danai Koutra</a>, and
              <a href="http://robertdick.org/">Robert P. Dick</a>
              <br>
              <em>Conference on Lifelong Learning Agents (CoLLAs)</em>, 2022
              <br>
              <a href="data/emr.bib">bibtex</a> / <a href="https://github.com/EkdeepSLubana/QRforgetting">github</a> / <a href="https://arxiv.org/abs/2102.02805">arXiv</a> / <a href="https://www.youtube.com/watch?v=gd5YzEnULHU">video</a> 
              <br>
              (Also presented at ICML Workshop on Theory and Foundations of Continual Learning, 2021) 
              <br>
              <p>This work demonstrates how quadratic regularization methods for preventing catastrophic forgetting in deep networks rely on a simple heuristic under-the-hood: Interpolation.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gradflow.png" alt="gradflow" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openreview.net/forum?id=rumv7QmLUue">
                <papertitle>A Gradient Flow Framework For Analyzing Network Pruning</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong> and
              <a href="http://robertdick.org/">Robert P. Dick</a>
              <br>
              <em>International Conference on Learning Representations (ICLR)</em>, 2021 <font color="red"> (Spotlight)</font> 
              <br>
              <a href="data/iclr.bib">bibtex</a> / <a href="https://github.com/EkdeepSLubana/flowandprune">github</a> / <a href="https://arxiv.org/abs/2009.11839">arXiv</a> / <a href="https://slideslive.com/38953851/a-gradient-flow-framework-for-analyzing-network-pruning">video</a> 
              <p>A unified, theoretically-grounded framework for network pruning that helps justify often used heuristics in the field.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Undergraduate Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/minsip.png" alt="minsip" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1HXnGcctlEI96S1edBIHjS88q5WM9a0h9/view?usp=sharing">
                <papertitle>Minimalistic Image Signal Processing for Deep Learning Applications</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              <a href="http://robertdick.org/">Robert P. Dick</a>,
              Vinayak Aggarwal, 
              <a href="https://www.iitr.ac.in/departments/ECE/pages/People+Faculty+Pyari_Mohan_Pradhan.html">Pyari Mohan Pradhan</a>
              <br>
              <em>International Conference on Image Processing (ICIP)</em>, 2019
              <br>
              <a href="data/icip.bib">bibtex</a> /
              <p>An image signal processing pipeline that allows use of out-of-the-box deep neural networks on RAW images directly retrieved from image sensors.</p>
            </td>
          </tr>


<!--           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/dcc.png" alt="Machine Foveation" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1L-xskJS_-MshExuuXkIPKwP_6p-zXjjQ/view?usp=sharing">
                <papertitle>Machine Foveation: An Application-Aware Compressive Sensing Framework</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              Vinayak Aggarwal, and
              <a href="http://robertdick.org/">Robert P. Dick</a>
              <br>
              <em>Data Compression Conference (DCC)</em>, 2019
              <br>
              <a href="data/mfoveation.bib">bibtex</a> /
              <p>An application-aware sampling framework that helps reduce processing energy by focusing on application-relevant regions only.</p>
            </td>
          </tr> -->


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/foveation.jpg" alt="Digital Foveation" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1WauNRLMVdzOEtlH4ZfawDAyBQiyV0p3I/view?usp=sharing">
                <papertitle>Digital Foveation: An Energy-Aware Machine Vision Framework</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong> and
              <a href="http://robertdick.org/">Robert P. Dick</a>
              <br>
              <em>IEEE Transactions on Computer-Aided Design of Integrated Circuits and System (TCAD)</em>, 2018
              <br>
              <a href="data/foveation.bib">bibtex</a> /
              <p>An energy-efficient machine vision framework inspired by the concept of Fovea in biological vision. Also see <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w40/Simpson_Intelligent_Scene_Caching_to_Improve_Accuracy_for_Energy-Constrained_Embedded_Vision_CVPRW_2020_paper.pdf">follow-up</a> work presented at CVPR workshop, 2020.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/snap.png" alt="SNAP" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1JGDjSyoXzOqPSNYTZ4aQjZJQjQVkhYpn/view?usp=sharing">
                <papertitle>Snap: Chlorophyll Concentration Calculator Using RAW Images of Leaves</papertitle>
              </a>
              <br>
              <strong>Ekdeep Singh Lubana</strong>,
              Mangesh Gurav, and
              <a href="https://www.ee.iitb.ac.in/web/people/faculty/home/mshojaei">Maryam Shojaei Baghini</a>
              <br>
              <em>IEEE Sensors</em>, 2018;
              <em> Global Winner, Ericsson Innovation Awards</em> 2017
              <br>
              <a href="data/snap.bib">bibtex</a> / <a href="https://www.ericsson.com/en/blog/2017/6/ericsson-innovation-awards-2017-working-together-for-the-future-of-food">news</a>
              <p>An efficient imaging system that accurately calculates chlorophyll content in leaves by using RAW images.</p>
            </td>
          </tr>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template source available <a href="https://github.com/jonbarron/jonbarron_website">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
